# Production Status & Testing Guide

## âœ… What's Working Now

### Local Development
- âœ… Workers running (3 processes active)
- âœ… Dev server running on `http://localhost:3001`
- âœ… Database connected (Neon Postgres)
- âœ… UI accessible at `/scraping` page
- âœ… Building Permits scraper implemented

### Production-Ready Features
- âœ… Vercel Cron configuration added
- âœ… Serverless scraping endpoint created (`/api/cron/scrape`)
- âœ… Automatic lead saving
- âœ… Session tracking
- âœ… Real-time UI updates (local)

---

## ğŸ§ª How to Test Right Now (Local)

### 1. Access the UI
Open your browser to: **`http://localhost:3001/scraping`**
(Note: Port 3001, not 3000!)

### 2. Start a Scraping Job
1. Enter a location: "Georgia" (or any US state)
2. Click **"Start Scraping"** button
3. Watch the console output in real-time
4. Workers will pick up the job within 5 seconds

### 3. Monitor Progress
- **Console Output**: Live logs from scrapers
- **Progress Bars**: Visual progress for each source
- **Session Status**: Current job details
- **Recent Sessions**: Historical job list

### 4. View Results
After scraping completes:
- Go to `/leads` page to see all leads
- Check lead details, scores, and priorities
- Filter by source, location, priority

---

## ğŸš€ How It Will Work in Production

### Current Limitation
**âŒ Workers cannot run on Vercel** because it's serverless

### Solution Implemented
**âœ… Vercel Cron Jobs** - Automatic scraping every 6 hours

### What Happens in Production:
1. **Automatic Scraping** (every 6 hours)
   - Vercel triggers `/api/cron/scrape`
   - Scrapes one location (rotates: GA, FL, CA, TX)
   - Saves leads automatically
   - No manual intervention needed

2. **Manual Scraping** (via UI)
   - User clicks "Start Scraping"
   - Creates a "pending" job in database
   - **Job will be processed** by next cron run OR
   - You can trigger immediately via API call

### Cron Schedule
```
"0 */6 * * *" = Every 6 hours
```

Times (EST): 12am, 6am, 12pm, 6pm

---

## ğŸ”§ What You Need to Do for Production

### Step 1: Set Environment Variables in Vercel
1. Go to: Vercel Dashboard â†’ Your Project â†’ Settings â†’ Environment Variables
2. Add these:
   ```
   CRON_SECRET=<generate-a-secure-random-key>
   DATABASE_URL=<your-neon-postgres-url>
   LLM_ENABLED=false
   ```

### Step 2: Generate CRON_SECRET
```bash
# Run this to generate a secure key:
node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
```

### Step 3: Deploy
```bash
git add .
git commit -m "Add production scraping via Vercel Cron"
git push origin main
```

### Step 4: Verify Cron Job
1. Go to Vercel Dashboard
2. Your Project â†’ Settings â†’ Cron Jobs
3. Should see: `/api/cron/scrape` - Every 6 hours

---

## ğŸ¯ Testing in Production

### Test Automatic Scraping
Wait for next cron execution (every 6 hours), or trigger manually:

```bash
curl -X GET https://your-app.vercel.app/api/cron/scrape \
  -H "Authorization: Bearer YOUR_CRON_SECRET"
```

**Expected Response:**
```json
{
  "success": true,
  "sessionId": 123,
  "location": "Georgia",
  "leadsFound": 45,
  "source": "Building Permits"
}
```

### Test Manual Scraping via UI
1. Go to `https://your-app.vercel.app/scraping`
2. Enter location
3. Click "Start Scraping"
4. Job created as "pending"
5. Next cron run will process it

---

## ğŸ“Š Monitoring Production Scraping

### View Results in UI
- **URL**: `https://your-app.vercel.app/scraping`
- Check "Recent Sessions" for completed jobs
- View lead count per session

### View Leads
- **URL**: `https://your-app.vercel.app/leads`
- All scraped leads display here
- Filter by date, source, priority

### View Function Logs (Vercel)
1. Vercel Dashboard â†’ Your Project
2. Click "Functions" tab
3. Find `/api/cron/scrape`
4. View execution history and logs

### View Database (Neon)
1. Neon Console â†’ Your Database
2. Tables â†’ `scraping_sessions` (job history)
3. Tables â†’ `leads` (scraped leads)

---

## ğŸ› Troubleshooting

### Local: No Activity
**Problem**: Workers running but no scraping happens

**Solution**:
1. Make sure you're on `http://localhost:3001` (not 3000)
2. Create a job by clicking "Start Scraping"
3. Check terminal with workers - should see activity within 5s
4. Verify database connection in `.env.local`

### Local: Workers Not Starting
**Problem**: `npm run workers:start` fails

**Solution**:
```bash
# Check if database is accessible
psql $DATABASE_URL -c "SELECT 1;"

# Restart workers
pkill -f "scraper-worker"
npm run workers:start
```

### Production: Cron Not Running
**Problem**: No automatic scraping happening

**Solution**:
1. Check Vercel Dashboard â†’ Cron Jobs tab
2. Verify execution history
3. Check function logs for errors
4. Confirm `CRON_SECRET` is set
5. Free tier allows 100 executions/day (6h schedule = 4/day)

### Production: Manual Jobs Stay "Pending"
**Problem**: UI creates job but it never processes

**Expected Behavior**: 
- Manual jobs in production will process on next cron run (up to 6 hours wait)
- For immediate processing, trigger cron endpoint manually

**Workaround**:
```bash
# Manually trigger processing
curl -X GET https://your-app.vercel.app/api/cron/scrape \
  -H "Authorization: Bearer YOUR_CRON_SECRET"
```

---

## ğŸ¨ UI Features Available

### Scraping Page (`/scraping`)
- âœ… Start/Stop scraping
- âœ… Real-time console logs (local only)
- âœ… Progress tracking per source
- âœ… Session history
- âœ… Live connection indicator
- âœ… Source configuration (enable/disable)

### Leads Page (`/leads`)
- âœ… Grid and table views
- âœ… Lead scoring and priority
- âœ… Detail modal with full information
- âœ… Filtering and search
- âœ… Export capabilities

### Workers Page (`/workers`)
- âœ… Worker health monitoring (local only)
- âœ… Job queue status
- âœ… Performance metrics

---

## ğŸ“ˆ What's Next

### Immediate (Can Test Now)
1. âœ… Test local scraping with workers
2. âœ… Verify leads appear in UI
3. âœ… Check session tracking

### Before Production Deploy
1. ğŸ”² Set up environment variables in Vercel
2. ğŸ”² Generate and save `CRON_SECRET`
3. ğŸ”² Test cron endpoint locally
4. ğŸ”² Deploy to Vercel

### Future Enhancements
1. ğŸ”² Add more scrapers (Reddit, Yelp, Craigslist)
2. ğŸ”² Implement LLM lead analysis
3. ğŸ”² Add email notifications for hot leads
4. ğŸ”² Create lead export functionality
5. ğŸ”² Add analytics dashboard

---

## ğŸ†˜ Quick Reference

### Local URLs
- Dev Server: `http://localhost:3001`
- Scraping Page: `http://localhost:3001/scraping`
- Leads Page: `http://localhost:3001/leads`
- Workers Page: `http://localhost:3001/workers`

### Important Commands
```bash
# Start development
npm run dev

# Start workers (separate terminal)
npm run workers:start

# Watch workers with auto-restart
npm run workers:dev

# Build for production
npm run build

# Check database
psql $DATABASE_URL
```

### Key Files
- `src/workers/scraper-worker.ts` - Worker implementation
- `src/workers/scrapers/permits.scraper.ts` - Permits scraper
- `src/app/api/cron/scrape/route.ts` - Production cron endpoint
- `vercel.json` - Cron job configuration
- `DEPLOYMENT_GUIDE.md` - Full deployment documentation

---

## ğŸ’¡ Pro Tips

1. **Local Development**: Always run workers in a separate terminal to see real-time logs
2. **Database**: Use Neon's query editor to inspect data directly
3. **Debugging**: Check both worker logs AND API logs for issues
4. **Production**: Set up Vercel notifications for cron failures
5. **Testing**: Use different locations to avoid hitting same sources repeatedly

---

## âœ¨ Current Status Summary

| Component | Status | Notes |
|-----------|--------|-------|
| Local Workers | âœ… Running | 3 workers active |
| Dev Server | âœ… Running | Port 3001 |
| Database | âœ… Connected | Neon Postgres |
| Permits Scraper | âœ… Working | Implemented |
| UI | âœ… Working | Full features |
| Vercel Cron | â³ Ready | Needs deployment |
| Production | â³ Pending | Needs env vars |

**Next Action**: Test local scraping at `http://localhost:3001/scraping` ğŸš€

